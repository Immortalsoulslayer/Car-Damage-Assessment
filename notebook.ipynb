{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 13:16:40.936522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:40.936540: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>dent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>tire flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>glass shatter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id filename  label           type\n",
       "0         1    1.jpg      2        scratch\n",
       "1         2    2.jpg      4           dent\n",
       "2         3    3.jpg      2        scratch\n",
       "3         4    4.jpg      3      tire flat\n",
       "4         5    5.jpg      5  glass shatter"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train/train.csv')\n",
    "\n",
    "damage_dict = {\n",
    "    1: 'crack',\n",
    "    2: 'scratch',\n",
    "    3: 'tire flat',\n",
    "    4: 'dent',\n",
    "    5: 'glass shatter',\n",
    "    6: 'lamp broken'\n",
    "}\n",
    "\n",
    "df['type'] = df['label'].map(damage_dict.get)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='type'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['type'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "scratch          1645\n",
      "dent             1455\n",
      "glass shatter     829\n",
      "lamp broken       618\n",
      "tire flat         374\n",
      "crack             119\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "type\n",
      "scratch          352\n",
      "dent             312\n",
      "glass shatter    178\n",
      "lamp broken      132\n",
      "tire flat         80\n",
      "crack             26\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "type\n",
      "scratch          352\n",
      "dent             312\n",
      "glass shatter    178\n",
      "lamp broken      132\n",
      "tire flat         80\n",
      "crack             26\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_intermediate, val = train_test_split(df, test_size = 0.15, stratify = df['type'])\n",
    "train, test = train_test_split(train_intermediate, test_size = 0.15 / (1 - 0.15), stratify = train_intermediate['type'])\n",
    "\n",
    "print(train['type'].value_counts(), '\\n')\n",
    "print(test['type'].value_counts(), '\\n')\n",
    "print(val['type'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = ''\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train1')\n",
    "val_dir = os.path.join(base_dir, 'val1')\n",
    "test_dir = os.path.join(base_dir, 'test1')\n",
    "\n",
    "if os.path.exists(base_dir):\n",
    "    shutil.rmtree(base_dir)\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "os.makedirs(train_dir)\n",
    "\n",
    "if os.path.exists(val_dir):\n",
    "    shutil.rmtree(val_dir)\n",
    "os.makedirs(val_dir)\n",
    "\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'train/images'\n",
    "\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "\n",
    "    diagnosis = row['type']\n",
    "    \n",
    "    id_code = str(row['image_id']) + \".jpg\"\n",
    "    train_dir = '/home/suraj/intern_work/Insurance_claim_detection/train1'\n",
    "\n",
    "    srcfile = os.path.join(src_dir,id_code)\n",
    "    dstfile = os.path.join(train_dir,diagnosis)\n",
    "\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)\n",
    "\n",
    "\n",
    "\n",
    "for index, row in val.iterrows():\n",
    "\n",
    "    diagnosis = row['type']\n",
    "    \n",
    "    id_code = str(row['image_id']) + \".jpg\"\n",
    "    val_dir = '/home/suraj/intern_work/Insurance_claim_detection/val1'\n",
    "\n",
    "    srcfile = os.path.join(src_dir, id_code)\n",
    "    dstfile = os.path.join(val_dir, diagnosis)\n",
    "\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)\n",
    " \n",
    "for index, row in test.iterrows():\n",
    "\n",
    "    diagnosis = row['type']\n",
    "\n",
    "    id_code = str(row['image_id']) + \".jpg\"\n",
    "    test_dir = '/home/suraj/intern_work/Insurance_claim_detection/test1'\n",
    "\n",
    "    srcfile = os.path.join(src_dir, id_code)\n",
    "    dstfile = os.path.join(test_dir, diagnosis)\n",
    "\n",
    "    os.makedirs(dstfile, exist_ok = True)\n",
    "    shutil.copy(srcfile, dstfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5040 images belonging to 6 classes.\n",
      "Found 1080 images belonging to 6 classes.\n",
      "Found 1080 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'train1'\n",
    "val_path = 'val1'\n",
    "test_path = 'test1'\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(train_path, target_size=(224,224))\n",
    "val_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_path, target_size=(224,224))\n",
    "test_batches = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_path, target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4800 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test = 'test'\n",
    "test_batchesk = ImageDataGenerator(rescale = 1./255).flow_from_directory(directory=test,target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 13:16:48.322057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-07 13:16:48.322274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322503: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322571: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-12-07 13:16:48.322577: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-07 13:16:48.323421: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/.local/lib/python3.10/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 47s 294ms/step - loss: 0.8730 - acc: 0.1889 - val_loss: 0.5292 - val_acc: 0.1630\n",
      "Epoch 2/150\n",
      "158/158 [==============================] - 47s 298ms/step - loss: 0.6533 - acc: 0.2843 - val_loss: 0.4523 - val_acc: 0.3361\n",
      "Epoch 3/150\n",
      "158/158 [==============================] - 45s 282ms/step - loss: 0.5509 - acc: 0.3468 - val_loss: 0.4253 - val_acc: 0.3750\n",
      "Epoch 4/150\n",
      "158/158 [==============================] - 48s 304ms/step - loss: 0.4945 - acc: 0.3815 - val_loss: 0.4123 - val_acc: 0.4157\n",
      "Epoch 5/150\n",
      "158/158 [==============================] - 43s 272ms/step - loss: 0.4606 - acc: 0.4085 - val_loss: 0.3982 - val_acc: 0.4444\n",
      "Epoch 6/150\n",
      "158/158 [==============================] - 42s 262ms/step - loss: 0.4344 - acc: 0.4224 - val_loss: 0.3842 - val_acc: 0.4620\n",
      "Epoch 7/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.4198 - acc: 0.4454 - val_loss: 0.3718 - val_acc: 0.4713\n",
      "Epoch 8/150\n",
      "158/158 [==============================] - 42s 268ms/step - loss: 0.4026 - acc: 0.4647 - val_loss: 0.3628 - val_acc: 0.4870\n",
      "Epoch 9/150\n",
      "158/158 [==============================] - 44s 276ms/step - loss: 0.3928 - acc: 0.4685 - val_loss: 0.3561 - val_acc: 0.4824\n",
      "Epoch 10/150\n",
      "158/158 [==============================] - 45s 282ms/step - loss: 0.3790 - acc: 0.4911 - val_loss: 0.3503 - val_acc: 0.4870\n",
      "Epoch 11/150\n",
      "158/158 [==============================] - 44s 277ms/step - loss: 0.3735 - acc: 0.5016 - val_loss: 0.3453 - val_acc: 0.4963\n",
      "Epoch 12/150\n",
      "158/158 [==============================] - 43s 271ms/step - loss: 0.3614 - acc: 0.5129 - val_loss: 0.3406 - val_acc: 0.5000\n",
      "Epoch 13/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.3539 - acc: 0.5304 - val_loss: 0.3370 - val_acc: 0.5083\n",
      "Epoch 14/150\n",
      "158/158 [==============================] - 43s 272ms/step - loss: 0.3494 - acc: 0.5306 - val_loss: 0.3334 - val_acc: 0.5167\n",
      "Epoch 15/150\n",
      "158/158 [==============================] - 43s 269ms/step - loss: 0.3401 - acc: 0.5530 - val_loss: 0.3305 - val_acc: 0.5278\n",
      "Epoch 16/150\n",
      "158/158 [==============================] - 43s 273ms/step - loss: 0.3344 - acc: 0.5563 - val_loss: 0.3268 - val_acc: 0.5241\n",
      "Epoch 17/150\n",
      "158/158 [==============================] - 47s 299ms/step - loss: 0.3293 - acc: 0.5673 - val_loss: 0.3246 - val_acc: 0.5315\n",
      "Epoch 18/150\n",
      "158/158 [==============================] - 50s 316ms/step - loss: 0.3241 - acc: 0.5720 - val_loss: 0.3223 - val_acc: 0.5370\n",
      "Epoch 19/150\n",
      "158/158 [==============================] - 49s 306ms/step - loss: 0.3182 - acc: 0.5821 - val_loss: 0.3198 - val_acc: 0.5370\n",
      "Epoch 20/150\n",
      "158/158 [==============================] - 49s 309ms/step - loss: 0.3117 - acc: 0.5958 - val_loss: 0.3170 - val_acc: 0.5454\n",
      "Epoch 21/150\n",
      "158/158 [==============================] - 47s 300ms/step - loss: 0.3060 - acc: 0.5970 - val_loss: 0.3148 - val_acc: 0.5435\n",
      "Epoch 22/150\n",
      "158/158 [==============================] - 49s 310ms/step - loss: 0.3034 - acc: 0.6067 - val_loss: 0.3125 - val_acc: 0.5546\n",
      "Epoch 23/150\n",
      "158/158 [==============================] - 45s 286ms/step - loss: 0.2988 - acc: 0.6188 - val_loss: 0.3100 - val_acc: 0.5528\n",
      "Epoch 24/150\n",
      "158/158 [==============================] - 48s 304ms/step - loss: 0.2911 - acc: 0.6298 - val_loss: 0.3084 - val_acc: 0.5639\n",
      "Epoch 25/150\n",
      "158/158 [==============================] - 49s 313ms/step - loss: 0.2888 - acc: 0.6361 - val_loss: 0.3066 - val_acc: 0.5685\n",
      "Epoch 26/150\n",
      "158/158 [==============================] - 49s 311ms/step - loss: 0.2853 - acc: 0.6359 - val_loss: 0.3049 - val_acc: 0.5676\n",
      "Epoch 27/150\n",
      "158/158 [==============================] - 51s 322ms/step - loss: 0.2762 - acc: 0.6563 - val_loss: 0.3027 - val_acc: 0.5750\n",
      "Epoch 28/150\n",
      "158/158 [==============================] - 50s 316ms/step - loss: 0.2725 - acc: 0.6671 - val_loss: 0.3020 - val_acc: 0.5833\n",
      "Epoch 29/150\n",
      "158/158 [==============================] - 47s 297ms/step - loss: 0.2690 - acc: 0.6639 - val_loss: 0.3003 - val_acc: 0.5824\n",
      "Epoch 30/150\n",
      "158/158 [==============================] - 47s 300ms/step - loss: 0.2666 - acc: 0.6800 - val_loss: 0.2976 - val_acc: 0.5926\n",
      "Epoch 31/150\n",
      "158/158 [==============================] - 46s 292ms/step - loss: 0.2637 - acc: 0.6798 - val_loss: 0.2959 - val_acc: 0.5917\n",
      "Epoch 32/150\n",
      "158/158 [==============================] - 51s 323ms/step - loss: 0.2560 - acc: 0.6946 - val_loss: 0.2942 - val_acc: 0.5944\n",
      "Epoch 33/150\n",
      "158/158 [==============================] - 47s 298ms/step - loss: 0.2552 - acc: 0.6964 - val_loss: 0.2928 - val_acc: 0.6046\n",
      "Epoch 34/150\n",
      "158/158 [==============================] - 49s 311ms/step - loss: 0.2497 - acc: 0.7131 - val_loss: 0.2908 - val_acc: 0.6046\n",
      "Epoch 35/150\n",
      "158/158 [==============================] - 47s 296ms/step - loss: 0.2464 - acc: 0.7071 - val_loss: 0.2895 - val_acc: 0.6037\n",
      "Epoch 36/150\n",
      "158/158 [==============================] - 46s 294ms/step - loss: 0.2440 - acc: 0.7083 - val_loss: 0.2875 - val_acc: 0.6130\n",
      "Epoch 37/150\n",
      "158/158 [==============================] - 47s 297ms/step - loss: 0.2385 - acc: 0.7220 - val_loss: 0.2865 - val_acc: 0.6120\n",
      "Epoch 38/150\n",
      "158/158 [==============================] - 47s 300ms/step - loss: 0.2370 - acc: 0.7319 - val_loss: 0.2858 - val_acc: 0.6167\n",
      "Epoch 39/150\n",
      "158/158 [==============================] - 47s 296ms/step - loss: 0.2336 - acc: 0.7345 - val_loss: 0.2842 - val_acc: 0.6148\n",
      "Epoch 40/150\n",
      "158/158 [==============================] - 48s 302ms/step - loss: 0.2295 - acc: 0.7411 - val_loss: 0.2822 - val_acc: 0.6185\n",
      "Epoch 41/150\n",
      "158/158 [==============================] - 50s 316ms/step - loss: 0.2259 - acc: 0.7490 - val_loss: 0.2814 - val_acc: 0.6148\n",
      "Epoch 42/150\n",
      "158/158 [==============================] - 51s 322ms/step - loss: 0.2221 - acc: 0.7562 - val_loss: 0.2796 - val_acc: 0.6194\n",
      "Epoch 43/150\n",
      "158/158 [==============================] - 50s 313ms/step - loss: 0.2194 - acc: 0.7512 - val_loss: 0.2776 - val_acc: 0.6241\n",
      "Epoch 44/150\n",
      "158/158 [==============================] - 49s 312ms/step - loss: 0.2123 - acc: 0.7724 - val_loss: 0.2764 - val_acc: 0.6315\n",
      "Epoch 45/150\n",
      "158/158 [==============================] - 49s 312ms/step - loss: 0.2094 - acc: 0.7788 - val_loss: 0.2750 - val_acc: 0.6315\n",
      "Epoch 46/150\n",
      "158/158 [==============================] - 50s 315ms/step - loss: 0.2042 - acc: 0.7841 - val_loss: 0.2737 - val_acc: 0.6324\n",
      "Epoch 47/150\n",
      "158/158 [==============================] - 50s 318ms/step - loss: 0.2028 - acc: 0.7873 - val_loss: 0.2728 - val_acc: 0.6389\n",
      "Epoch 48/150\n",
      "158/158 [==============================] - 47s 295ms/step - loss: 0.1994 - acc: 0.7942 - val_loss: 0.2720 - val_acc: 0.6417\n",
      "Epoch 49/150\n",
      "158/158 [==============================] - 47s 297ms/step - loss: 0.1945 - acc: 0.8004 - val_loss: 0.2700 - val_acc: 0.6444\n",
      "Epoch 50/150\n",
      "158/158 [==============================] - 48s 301ms/step - loss: 0.1946 - acc: 0.8028 - val_loss: 0.2692 - val_acc: 0.6481\n",
      "Epoch 51/150\n",
      "158/158 [==============================] - 46s 289ms/step - loss: 0.1902 - acc: 0.8079 - val_loss: 0.2681 - val_acc: 0.6426\n",
      "Epoch 52/150\n",
      "158/158 [==============================] - 44s 280ms/step - loss: 0.1888 - acc: 0.8121 - val_loss: 0.2671 - val_acc: 0.6472\n",
      "Epoch 53/150\n",
      "158/158 [==============================] - 49s 309ms/step - loss: 0.1826 - acc: 0.8238 - val_loss: 0.2659 - val_acc: 0.6528\n",
      "Epoch 54/150\n",
      "158/158 [==============================] - 49s 312ms/step - loss: 0.1832 - acc: 0.8185 - val_loss: 0.2649 - val_acc: 0.6528\n",
      "Epoch 55/150\n",
      "158/158 [==============================] - 51s 320ms/step - loss: 0.1768 - acc: 0.8292 - val_loss: 0.2637 - val_acc: 0.6546\n",
      "Epoch 56/150\n",
      "158/158 [==============================] - 49s 311ms/step - loss: 0.1744 - acc: 0.8349 - val_loss: 0.2627 - val_acc: 0.6593\n",
      "Epoch 57/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.1691 - acc: 0.8421 - val_loss: 0.2610 - val_acc: 0.6676\n",
      "Epoch 58/150\n",
      "158/158 [==============================] - 46s 289ms/step - loss: 0.1662 - acc: 0.8502 - val_loss: 0.2606 - val_acc: 0.6676\n",
      "Epoch 59/150\n",
      "158/158 [==============================] - 45s 287ms/step - loss: 0.1635 - acc: 0.8532 - val_loss: 0.2594 - val_acc: 0.6667\n",
      "Epoch 60/150\n",
      "158/158 [==============================] - 45s 283ms/step - loss: 0.1639 - acc: 0.8433 - val_loss: 0.2588 - val_acc: 0.6685\n",
      "Epoch 61/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.1600 - acc: 0.8474 - val_loss: 0.2575 - val_acc: 0.6704\n",
      "Epoch 62/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.1545 - acc: 0.8661 - val_loss: 0.2566 - val_acc: 0.6741\n",
      "Epoch 63/150\n",
      "158/158 [==============================] - 45s 282ms/step - loss: 0.1494 - acc: 0.8764 - val_loss: 0.2562 - val_acc: 0.6722\n",
      "Epoch 64/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.1491 - acc: 0.8766 - val_loss: 0.2550 - val_acc: 0.6750\n",
      "Epoch 65/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.1469 - acc: 0.8794 - val_loss: 0.2552 - val_acc: 0.6833\n",
      "Epoch 66/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.1478 - acc: 0.8744 - val_loss: 0.2536 - val_acc: 0.6806\n",
      "Epoch 67/150\n",
      "158/158 [==============================] - 46s 288ms/step - loss: 0.1423 - acc: 0.8835 - val_loss: 0.2523 - val_acc: 0.6843\n",
      "Epoch 68/150\n",
      "158/158 [==============================] - 45s 283ms/step - loss: 0.1385 - acc: 0.8895 - val_loss: 0.2515 - val_acc: 0.6806\n",
      "Epoch 69/150\n",
      "158/158 [==============================] - 45s 282ms/step - loss: 0.1382 - acc: 0.8927 - val_loss: 0.2514 - val_acc: 0.6898\n",
      "Epoch 70/150\n",
      "158/158 [==============================] - 45s 283ms/step - loss: 0.1363 - acc: 0.8897 - val_loss: 0.2504 - val_acc: 0.6843\n",
      "Epoch 71/150\n",
      "158/158 [==============================] - 45s 287ms/step - loss: 0.1304 - acc: 0.8994 - val_loss: 0.2499 - val_acc: 0.6861\n",
      "Epoch 72/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.1292 - acc: 0.9069 - val_loss: 0.2499 - val_acc: 0.6870\n",
      "Epoch 73/150\n",
      "158/158 [==============================] - 47s 299ms/step - loss: 0.1283 - acc: 0.9006 - val_loss: 0.2489 - val_acc: 0.6852\n",
      "Epoch 74/150\n",
      "158/158 [==============================] - 49s 307ms/step - loss: 0.1229 - acc: 0.9157 - val_loss: 0.2479 - val_acc: 0.6870\n",
      "Epoch 75/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.1231 - acc: 0.9087 - val_loss: 0.2475 - val_acc: 0.6963\n",
      "Epoch 76/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.1208 - acc: 0.9177 - val_loss: 0.2463 - val_acc: 0.6944\n",
      "Epoch 77/150\n",
      "158/158 [==============================] - 49s 309ms/step - loss: 0.1172 - acc: 0.9143 - val_loss: 0.2453 - val_acc: 0.6954\n",
      "Epoch 78/150\n",
      "158/158 [==============================] - 47s 298ms/step - loss: 0.1147 - acc: 0.9167 - val_loss: 0.2441 - val_acc: 0.7028\n",
      "Epoch 79/150\n",
      "158/158 [==============================] - 50s 317ms/step - loss: 0.1125 - acc: 0.9230 - val_loss: 0.2445 - val_acc: 0.7000\n",
      "Epoch 80/150\n",
      "158/158 [==============================] - 47s 294ms/step - loss: 0.1091 - acc: 0.9310 - val_loss: 0.2433 - val_acc: 0.7019\n",
      "Epoch 81/150\n",
      "158/158 [==============================] - 48s 303ms/step - loss: 0.1080 - acc: 0.9270 - val_loss: 0.2434 - val_acc: 0.7065\n",
      "Epoch 82/150\n",
      "158/158 [==============================] - 47s 295ms/step - loss: 0.1076 - acc: 0.9230 - val_loss: 0.2433 - val_acc: 0.7046\n",
      "Epoch 83/150\n",
      "158/158 [==============================] - 47s 296ms/step - loss: 0.1041 - acc: 0.9355 - val_loss: 0.2420 - val_acc: 0.7083\n",
      "Epoch 84/150\n",
      "158/158 [==============================] - 47s 296ms/step - loss: 0.1022 - acc: 0.9325 - val_loss: 0.2411 - val_acc: 0.7065\n",
      "Epoch 85/150\n",
      "158/158 [==============================] - 48s 302ms/step - loss: 0.0998 - acc: 0.9373 - val_loss: 0.2411 - val_acc: 0.7093\n",
      "Epoch 86/150\n",
      "158/158 [==============================] - 45s 287ms/step - loss: 0.0964 - acc: 0.9433 - val_loss: 0.2399 - val_acc: 0.7139\n",
      "Epoch 87/150\n",
      "158/158 [==============================] - 49s 312ms/step - loss: 0.0970 - acc: 0.9399 - val_loss: 0.2407 - val_acc: 0.7148\n",
      "Epoch 88/150\n",
      "158/158 [==============================] - 50s 315ms/step - loss: 0.0942 - acc: 0.9460 - val_loss: 0.2403 - val_acc: 0.7074\n",
      "Epoch 89/150\n",
      "158/158 [==============================] - 48s 302ms/step - loss: 0.0935 - acc: 0.9448 - val_loss: 0.2411 - val_acc: 0.7139\n",
      "Epoch 90/150\n",
      "158/158 [==============================] - 53s 337ms/step - loss: 0.0888 - acc: 0.9488 - val_loss: 0.2395 - val_acc: 0.7102\n",
      "Epoch 91/150\n",
      "158/158 [==============================] - 50s 313ms/step - loss: 0.0856 - acc: 0.9548 - val_loss: 0.2385 - val_acc: 0.7176\n",
      "Epoch 92/150\n",
      "158/158 [==============================] - 48s 305ms/step - loss: 0.0865 - acc: 0.9530 - val_loss: 0.2384 - val_acc: 0.7194\n",
      "Epoch 93/150\n",
      "158/158 [==============================] - 47s 295ms/step - loss: 0.0845 - acc: 0.9554 - val_loss: 0.2376 - val_acc: 0.7204\n",
      "Epoch 94/150\n",
      "158/158 [==============================] - 46s 290ms/step - loss: 0.0821 - acc: 0.9569 - val_loss: 0.2381 - val_acc: 0.7176\n",
      "Epoch 95/150\n",
      "158/158 [==============================] - 46s 293ms/step - loss: 0.0827 - acc: 0.9548 - val_loss: 0.2371 - val_acc: 0.7222\n",
      "Epoch 96/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0790 - acc: 0.9587 - val_loss: 0.2386 - val_acc: 0.7185\n",
      "Epoch 97/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0786 - acc: 0.9627 - val_loss: 0.2372 - val_acc: 0.7231\n",
      "Epoch 98/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0755 - acc: 0.9615 - val_loss: 0.2376 - val_acc: 0.7213\n",
      "Epoch 99/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0746 - acc: 0.9639 - val_loss: 0.2380 - val_acc: 0.7241\n",
      "Epoch 100/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0722 - acc: 0.9639 - val_loss: 0.2369 - val_acc: 0.7269\n",
      "Epoch 101/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0714 - acc: 0.9669 - val_loss: 0.2369 - val_acc: 0.7250\n",
      "Epoch 102/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0696 - acc: 0.9681 - val_loss: 0.2367 - val_acc: 0.7306\n",
      "Epoch 103/150\n",
      "158/158 [==============================] - 42s 268ms/step - loss: 0.0680 - acc: 0.9702 - val_loss: 0.2354 - val_acc: 0.7250\n",
      "Epoch 104/150\n",
      "158/158 [==============================] - 42s 268ms/step - loss: 0.0666 - acc: 0.9698 - val_loss: 0.2350 - val_acc: 0.7343\n",
      "Epoch 105/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0630 - acc: 0.9734 - val_loss: 0.2354 - val_acc: 0.7259\n",
      "Epoch 106/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0642 - acc: 0.9730 - val_loss: 0.2346 - val_acc: 0.7333\n",
      "Epoch 107/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0614 - acc: 0.9744 - val_loss: 0.2356 - val_acc: 0.7287\n",
      "Epoch 108/150\n",
      "158/158 [==============================] - 42s 268ms/step - loss: 0.0610 - acc: 0.9766 - val_loss: 0.2346 - val_acc: 0.7315\n",
      "Epoch 109/150\n",
      "158/158 [==============================] - 42s 268ms/step - loss: 0.0594 - acc: 0.9760 - val_loss: 0.2357 - val_acc: 0.7352\n",
      "Epoch 110/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0570 - acc: 0.9806 - val_loss: 0.2342 - val_acc: 0.7398\n",
      "Epoch 111/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0563 - acc: 0.9802 - val_loss: 0.2360 - val_acc: 0.7389\n",
      "Epoch 112/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0565 - acc: 0.9788 - val_loss: 0.2360 - val_acc: 0.7417\n",
      "Epoch 113/150\n",
      "158/158 [==============================] - 42s 264ms/step - loss: 0.0558 - acc: 0.9772 - val_loss: 0.2367 - val_acc: 0.7343\n",
      "Epoch 114/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0529 - acc: 0.9825 - val_loss: 0.2349 - val_acc: 0.7454\n",
      "Epoch 115/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0517 - acc: 0.9813 - val_loss: 0.2353 - val_acc: 0.7380\n",
      "Epoch 116/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0501 - acc: 0.9829 - val_loss: 0.2350 - val_acc: 0.7417\n",
      "Epoch 117/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0480 - acc: 0.9827 - val_loss: 0.2351 - val_acc: 0.7444\n",
      "Epoch 118/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0487 - acc: 0.9837 - val_loss: 0.2356 - val_acc: 0.7481\n",
      "Epoch 119/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0473 - acc: 0.9821 - val_loss: 0.2347 - val_acc: 0.7426\n",
      "Epoch 120/150\n",
      "158/158 [==============================] - 42s 263ms/step - loss: 0.0461 - acc: 0.9861 - val_loss: 0.2350 - val_acc: 0.7472\n",
      "Epoch 121/150\n",
      "158/158 [==============================] - 42s 263ms/step - loss: 0.0449 - acc: 0.9857 - val_loss: 0.2363 - val_acc: 0.7444\n",
      "Epoch 122/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0447 - acc: 0.9873 - val_loss: 0.2357 - val_acc: 0.7398\n",
      "Epoch 123/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0434 - acc: 0.9877 - val_loss: 0.2362 - val_acc: 0.7463\n",
      "Epoch 124/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0414 - acc: 0.9897 - val_loss: 0.2380 - val_acc: 0.7444\n",
      "Epoch 125/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0405 - acc: 0.9893 - val_loss: 0.2368 - val_acc: 0.7454\n",
      "Epoch 126/150\n",
      "158/158 [==============================] - 42s 264ms/step - loss: 0.0401 - acc: 0.9889 - val_loss: 0.2373 - val_acc: 0.7454\n",
      "Epoch 127/150\n",
      "158/158 [==============================] - 42s 266ms/step - loss: 0.0392 - acc: 0.9891 - val_loss: 0.2376 - val_acc: 0.7407\n",
      "Epoch 128/150\n",
      "158/158 [==============================] - 42s 267ms/step - loss: 0.0380 - acc: 0.9899 - val_loss: 0.2387 - val_acc: 0.7463\n",
      "Epoch 129/150\n",
      "158/158 [==============================] - 42s 265ms/step - loss: 0.0369 - acc: 0.9891 - val_loss: 0.2395 - val_acc: 0.7481\n",
      "Epoch 130/150\n",
      "158/158 [==============================] - 44s 278ms/step - loss: 0.0366 - acc: 0.9919 - val_loss: 0.2382 - val_acc: 0.7435\n",
      "Epoch 131/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.0366 - acc: 0.9917 - val_loss: 0.2380 - val_acc: 0.7509\n",
      "Epoch 132/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.0344 - acc: 0.9909 - val_loss: 0.2377 - val_acc: 0.7509\n",
      "Epoch 133/150\n",
      "158/158 [==============================] - 46s 287ms/step - loss: 0.0348 - acc: 0.9903 - val_loss: 0.2386 - val_acc: 0.7472\n",
      "Epoch 134/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.0333 - acc: 0.9931 - val_loss: 0.2383 - val_acc: 0.7509\n",
      "Epoch 135/150\n",
      "158/158 [==============================] - 45s 287ms/step - loss: 0.0313 - acc: 0.9919 - val_loss: 0.2408 - val_acc: 0.7491\n",
      "Epoch 136/150\n",
      "158/158 [==============================] - 45s 283ms/step - loss: 0.0330 - acc: 0.9929 - val_loss: 0.2397 - val_acc: 0.7481\n",
      "Epoch 137/150\n",
      "158/158 [==============================] - 46s 293ms/step - loss: 0.0308 - acc: 0.9952 - val_loss: 0.2409 - val_acc: 0.7500\n",
      "Epoch 138/150\n",
      "158/158 [==============================] - 45s 286ms/step - loss: 0.0308 - acc: 0.9938 - val_loss: 0.2408 - val_acc: 0.7500\n",
      "Epoch 139/150\n",
      "158/158 [==============================] - 45s 287ms/step - loss: 0.0292 - acc: 0.9954 - val_loss: 0.2411 - val_acc: 0.7574\n",
      "Epoch 140/150\n",
      "158/158 [==============================] - 46s 289ms/step - loss: 0.0288 - acc: 0.9948 - val_loss: 0.2414 - val_acc: 0.7528\n",
      "Epoch 141/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.0282 - acc: 0.9950 - val_loss: 0.2426 - val_acc: 0.7491\n",
      "Epoch 142/150\n",
      "158/158 [==============================] - 45s 283ms/step - loss: 0.0284 - acc: 0.9946 - val_loss: 0.2444 - val_acc: 0.7500\n",
      "Epoch 143/150\n",
      "158/158 [==============================] - 45s 286ms/step - loss: 0.0266 - acc: 0.9962 - val_loss: 0.2438 - val_acc: 0.7574\n",
      "Epoch 144/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.0280 - acc: 0.9946 - val_loss: 0.2437 - val_acc: 0.7509\n",
      "Epoch 145/150\n",
      "158/158 [==============================] - 45s 282ms/step - loss: 0.0271 - acc: 0.9938 - val_loss: 0.2450 - val_acc: 0.7519\n",
      "Epoch 146/150\n",
      "158/158 [==============================] - 45s 283ms/step - loss: 0.0259 - acc: 0.9958 - val_loss: 0.2439 - val_acc: 0.7509\n",
      "Epoch 147/150\n",
      "158/158 [==============================] - 45s 285ms/step - loss: 0.0235 - acc: 0.9960 - val_loss: 0.2440 - val_acc: 0.7583\n",
      "Epoch 148/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.0247 - acc: 0.9964 - val_loss: 0.2437 - val_acc: 0.7611\n",
      "Epoch 149/150\n",
      "158/158 [==============================] - 45s 284ms/step - loss: 0.0232 - acc: 0.9970 - val_loss: 0.2457 - val_acc: 0.7546\n",
      "Epoch 150/150\n",
      "158/158 [==============================] - 45s 286ms/step - loss: 0.0235 - acc: 0.9968 - val_loss: 0.2453 - val_acc: 0.7537\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(8, (3,3), padding=\"valid\", input_shape=(224,224,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    layers.Conv2D(16, (3,3), padding=\"valid\", activation = 'relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    layers.Conv2D(32, (3,3), padding=\"valid\", activation = 'sigmoid'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding=\"valid\", activation = 'relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(128, (4,4), padding=\"valid\", activation = 'relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    " \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation = 'relu'),\n",
    "    layers.Dropout(0.27),\n",
    "    layers.Dense(6, activation = 'softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=150,\n",
    "                    validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('prime_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel=load_model('prime_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8552/2284690981.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  loss, acc = savedModel.evaluate_generator(test_batches, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 142ms/step - loss: 0.2378 - acc: 0.7500\n",
      "Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "loss, acc = savedModel.evaluate_generator(test_batches, verbose=1)\n",
    "# print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 21s 142ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayk = savedModel.predict(test_batchesk, verbose=1)\n",
    "len(arrayk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.array(arrayk)\n",
    "\n",
    "l = []\n",
    "for i in range(len(arrayk)):\n",
    "    l.append(np.argmax(arrayk[i]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.array(l)\n",
    "\n",
    "sb = pd.DataFrame({'image_id': test_batchesk.filenames, 'label': dt})\n",
    "\n",
    "damage_dict = {\n",
    "    0: 'crack',\n",
    "    1: 'scratch',\n",
    "    2: 'tire flat',\n",
    "    3: 'dent',\n",
    "    4: 'glass shatter',\n",
    "    5: 'lamp broken'\n",
    "}\n",
    "\n",
    "sb['type'] = sb['label'].map(damage_dict.get)\n",
    "sb.head()\n",
    "\n",
    "sb.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
